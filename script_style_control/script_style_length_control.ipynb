{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tiktoken\n",
        "!pip install -U shortuuid\n",
        "!pip install -U transformers==4.45.2\n",
        "!pip install -U datasets\n",
        "!pip install -U rouge-score\n",
        "!pip install -U pymorphy3\n",
        "!pip install -U peft\n",
        "!pip install -U evalica"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVD96FIutrPM",
        "outputId": "629b3f75-74ae-4fc0-cd27-eab233523415"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Collecting shortuuid\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: shortuuid\n",
            "Successfully installed shortuuid-1.0.13\n",
            "Collecting transformers==4.45.2\n",
            "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (0.5.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.2)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (2025.4.26)\n",
            "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "Successfully installed tokenizers-0.20.3 transformers-4.45.2\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d66ceeae38f55c4c38d32b22f536f329fcb5540150eb42a03946a1fdccf97c03\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.45.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting evalica\n",
            "  Downloading evalica-0.3.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from evalica) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evalica) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evalica) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evalica) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evalica) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evalica) (1.17.0)\n",
            "Downloading evalica-0.3.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (369 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.7/369.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evalica\n",
            "Successfully installed evalica-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VzzE-8KxVnIt"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Tuple\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from evalica import bradley_terry, Winner, pairwise_frame\n",
        "from functools import partial\n",
        "from scipy.special import expit\n",
        "from scipy.optimize import minimize\n",
        "from math import log\n",
        "from random import randint\n",
        "import re\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STYLE_CONTROL_ELEMENTS = [\n",
        "    \"len_answer\",\n",
        "    \"header_count\",\n",
        "    \"list_count\",\n",
        "    \"bold_count\",\n",
        "    \"code_blocks_count\"\n",
        "]\n",
        "\n",
        "DIFF_MASK = np.array([1.0, -1.0], dtype=np.float64)\n",
        "\n",
        "def count_style_elements(markdown_text):\n",
        "    def remove_pattern(answer, pattern):\n",
        "        blocks = pattern.findall(answer)\n",
        "        for block in blocks:\n",
        "            answer = answer.replace(block, \"\")\n",
        "        return answer\n",
        "\n",
        "    len_answer = len(markdown_text)\n",
        "    code_count = len(re.findall(r\"```[^`]+```\", markdown_text))\n",
        "    code_pattern = re.compile(\"```([^`]+)```\")\n",
        "    markdown_text = remove_pattern(markdown_text, code_pattern)\n",
        "    markdown_text = markdown_text.replace(\"```\", \"\")\n",
        "\n",
        "    mono_count = len(re.findall(r\"`[^`]+`\", markdown_text))\n",
        "    mono_pattern = re.compile(\"`([^`]+)`\")\n",
        "    markdown_text = remove_pattern(markdown_text, mono_pattern)\n",
        "    counters = {\n",
        "        f\"len_answer\": len_answer,\n",
        "        f\"header_count\": {\n",
        "            \"h1\": len(re.findall(r\"^#{1}\\s\", markdown_text, re.MULTILINE)),\n",
        "            \"h2\": len(re.findall(r\"^#{2}\\s\", markdown_text, re.MULTILINE)),\n",
        "            \"h3\": len(re.findall(r\"^#{3}\\s\", markdown_text, re.MULTILINE)),\n",
        "            \"h4\": len(re.findall(r\"^#{4}\\s\", markdown_text, re.MULTILINE)),\n",
        "            \"h5\": len(re.findall(r\"^#{5}\\s\", markdown_text, re.MULTILINE)),\n",
        "            \"h6\": len(re.findall(r\"^#{6}\\s\", markdown_text, re.MULTILINE)),\n",
        "        },\n",
        "        f\"list_count\": {\n",
        "            \"ordered\": len(re.findall(r\"^\\s*\\d+\\.\\s\", markdown_text, re.MULTILINE)),\n",
        "            \"unordered\": len(re.findall(r\"^\\s*[-*+]\\s\", markdown_text, re.MULTILINE)),\n",
        "        },\n",
        "        f\"bold_count\": {\n",
        "            \"**\": len(re.findall(r\"\\*\\*[^*\\n]+\\*\\*\", markdown_text)),\n",
        "            \"__\": len(re.findall(r\"__[^_\\n]+__\", markdown_text)),\n",
        "        },\n",
        "        f\"code_blocks_count\": {\n",
        "            \"`\": mono_count,\n",
        "            \"```\": code_count,\n",
        "        },\n",
        "    }\n",
        "    return counters\n",
        "\n",
        "\n",
        "def extract_style_feature(x, feature):\n",
        "    val = x[feature]\n",
        "    if isinstance(val, int):\n",
        "        return val\n",
        "    else:\n",
        "        return sum(val.values())\n",
        "\n",
        "\n",
        "def get_element_counts(text):\n",
        "    style_elements = count_style_elements(text)\n",
        "    el_counts = []\n",
        "    for feature in style_elements:\n",
        "        el_counts.append(extract_style_feature(style_elements, feature))\n",
        "    return el_counts\n",
        "\n",
        "\n",
        "def calculate_style(\n",
        "    model_a: pd.Series,\n",
        "    model_b: pd.Series,\n",
        "    style_elements: list[str]=STYLE_CONTROL_ELEMENTS\n",
        "):\n",
        "    n_features = len(style_elements)\n",
        "    n_battles = model_a.shape[0]\n",
        "    style_matrix = np.zeros(shape=(2*n_features, n_battles))\n",
        "    for idx, element in enumerate(style_elements):\n",
        "        style_matrix[idx, :] = np.array([el[idx] for el in model_a])\n",
        "    for idx, element in enumerate(style_elements):\n",
        "        style_matrix[n_features + idx, :] = np.array([el[idx] for el in model_b])\n",
        "    style_diff = (style_matrix[:n_features] - style_matrix[n_features]).astype(float)\n",
        "    style_sum = (style_matrix[:n_features] + style_matrix[n_features]).astype(float)\n",
        "\n",
        "    style_diff /= style_sum\n",
        "\n",
        "    style_mean = np.mean(style_diff, axis=1)\n",
        "    style_std = np.std(style_diff, axis=1)\n",
        "    features = ((style_diff - style_mean[:, np.newaxis]) / style_std[:, np.newaxis]).T\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_matchups_models(model_a: pd.Series, model_b: pd.Series):\n",
        "    n_rows = len(model_a)\n",
        "    assert len(model_b) == n_rows\n",
        "    model_indices, models = pd.factorize(pd.concat([model_a, model_b]))\n",
        "    matchups = np.column_stack([model_indices[:n_rows], model_indices[n_rows:]])\n",
        "    return matchups, models.to_list()\n",
        "\n",
        "\n",
        "def contextual_bt_loss_and_grad(\n",
        "    params,\n",
        "    n_competitors,\n",
        "    matchups,\n",
        "    features,\n",
        "    outcomes,\n",
        "    alpha=1.0,\n",
        "    reg=1.0,\n",
        "    half_reg=0.5,\n",
        "):\n",
        "    reg_loss = half_reg * np.inner(params, params)\n",
        "\n",
        "    ratings = params[:n_competitors]\n",
        "    feature_params = params[n_competitors:]\n",
        "\n",
        "    matchup_ratings = ratings[matchups]\n",
        "\n",
        "    bt_logits = alpha * (matchup_ratings[:, 0] - matchup_ratings[:, 1])\n",
        "    context_logits = np.dot(features, feature_params)\n",
        "    probs = expit(bt_logits + context_logits)\n",
        "    loss = (\n",
        "        -((np.log(probs) * outcomes + np.log(1.0 - probs) * (1.0 - outcomes))).sum()\n",
        "        + reg_loss\n",
        "    )\n",
        "\n",
        "    error = outcomes - probs\n",
        "    grad = reg * params\n",
        "    matchups_grads = -alpha * error\n",
        "    np.add.at(\n",
        "        grad[:n_competitors], matchups[:, [0, 1]], matchups_grads[:, None] * DIFF_MASK\n",
        "    )\n",
        "    grad[n_competitors:] -= np.dot(features.T, error)\n",
        "\n",
        "    return loss, grad, expit(context_logits)\n",
        "\n",
        "\n",
        "def fit_contextual_bt(\n",
        "    matchups,\n",
        "    features,\n",
        "    outcomes,\n",
        "    models,\n",
        "    idxs=None,\n",
        "    alpha=log(10.0),\n",
        "    reg=0.5,\n",
        "    tol=1e-6,\n",
        "):\n",
        "    n_features = features.shape[1]\n",
        "    n_models = len(models)\n",
        "    initial_params = np.zeros(n_models + n_features, dtype=np.float64)\n",
        "    half_reg = reg / 2.0\n",
        "\n",
        "    if idxs is not None:\n",
        "        matchups, features, outcomes = matchups[idxs], features[idxs], outcomes[idxs]\n",
        "\n",
        "    result = minimize(\n",
        "        fun=contextual_bt_loss_and_grad,\n",
        "        x0=initial_params,\n",
        "        args=(n_models, matchups, features, outcomes, alpha, reg, half_reg),\n",
        "        jac=True,\n",
        "        method=\"L-BFGS-B\",\n",
        "        options={\"disp\": False, \"maxiter\": 100, \"gtol\": tol},\n",
        "    )\n",
        "    loss, grad, context_logits = contextual_bt_loss_and_grad(result[\"x\"], n_models, matchups, features, outcomes, alpha, reg, half_reg)\n",
        "    return result[\"x\"], context_logits\n",
        "\n",
        "\n",
        "def compute_style_control(\n",
        "    df: pd.DataFrame,\n",
        "    alpha=log(10.0), reg=0.5, tol=1e-6\n",
        "):\n",
        "    features = calculate_style(df.model_a_style, df.model_b_style)\n",
        "    matchups, models = get_matchups_models(df.model_a, df.model_b)\n",
        "    outcomes = df.winner.values\n",
        "    params, context_logits = fit_contextual_bt(\n",
        "        matchups,\n",
        "        features,\n",
        "        outcomes,\n",
        "        models=models,\n",
        "        alpha=alpha,\n",
        "        reg=reg,\n",
        "        tol=tol,\n",
        "    )\n",
        "    ratings = params[: len(models)]\n",
        "    weigths = params[len(models):]\n",
        "    return ratings, models, context_logits\n",
        "\n",
        "def scale_and_offset(\n",
        "    ratings,\n",
        "    models=[],\n",
        "    baseline_model='',\n",
        "    scale=400,\n",
        "    init_rating=1000,\n",
        "    baseline_rating=1114,\n",
        "):\n",
        "    \"\"\"convert ratings from the natural scale to the Elo rating scale with an anchored baseline\"\"\"\n",
        "    scaled_ratings = (ratings * scale) + init_rating\n",
        "    if baseline_model and models and baseline_model in models:\n",
        "        baseline_idx = models.index(baseline_model)\n",
        "        scaled_ratings += baseline_rating - scaled_ratings[..., [baseline_idx]]\n",
        "    return scaled_ratings"
      ],
      "metadata": {
        "id": "kSOIzCJmBYBn"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict, Tuple, Union\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-atOr_XWOvxj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_battles_to_json(filename: str, results: List[Dict]=[]):\n",
        "    if not results:\n",
        "        return\n",
        "    if not filename:\n",
        "        filename = \"battles_saved_file.json\"\n",
        "    try:\n",
        "      with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('[\\n')\n",
        "        for i, item in enumerate(results):\n",
        "            line = json.dumps(item, ensure_ascii=False)\n",
        "            if i < len(results) - 1:\n",
        "                line += ','\n",
        "            f.write(f'  {line}\\n')\n",
        "        f.write(']')\n",
        "    except Exception as e:\n",
        "        print(f\"Error with file {filename}: {e}.\")\n",
        "    else:\n",
        "        print(f\"Data was stored to {filename}.\")"
      ],
      "metadata": {
        "id": "6-II13K-Myvl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _prepare_data(\n",
        "    results: List[Dict],\n",
        "    len_control: bool=False,\n",
        "    style_control: bool=True,\n",
        "    pen_only_model: bool=False\n",
        "  ) -> list:\n",
        "\n",
        "    if style_control:\n",
        "        for r in results:\n",
        "            if 'styles' not in r:\n",
        "                raise ValueError(\"If the 'style_control' mode is on, the data should contain information about the style of model answers.\")\n",
        "\n",
        "    if len_control:\n",
        "        for r in results:\n",
        "            if 'lens' not in r:\n",
        "                if 'styles' in r:\n",
        "                    r['lens'] = {'model': r['styles']['model'][0], 'reference': r['styles']['reference'][0]}\n",
        "                else:\n",
        "                    raise ValueError(\"If the 'len_control' mode is on, the data should contain information about the length of model answers.\")\n",
        "\n",
        "    full_hash =  ['|'.join([str(r['id']), r['model_name'], r['reference_model_name']]) for r in results]\n",
        "    model_hash = ['|'.join([str(r['id']), r['model_name']]) for r in results]\n",
        "    reference_hash = ['|'.join([str(r['id']), r['reference_model_name']]) for r in results]\n",
        "\n",
        "    data = []\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['p'] = [r['p'] for r in results]\n",
        "    df['full_hash'] = full_hash\n",
        "    df['model_hash'] = model_hash\n",
        "    df['reference_hash'] = reference_hash\n",
        "\n",
        "    df['model_name'] = [r['model_name'] for r in results]\n",
        "    df['reference_model_name'] = [r['reference_model_name'] for r in results]\n",
        "\n",
        "    if style_control:\n",
        "        df['model_style'] = [np.array(r['styles']['model']) for r in results]\n",
        "        df['reference_style'] = [np.array(r['styles']['reference']) for r in results]\n",
        "    elif len_control:\n",
        "        df['model_len'] = [r['lens']['model'] for r in results]\n",
        "        df['reference_len'] = [r['lens']['reference'] for r in results]\n",
        "\n",
        "        answer_len_deltas = {}\n",
        "        for ref_model_name, group in df.groupby('reference_model_name'):\n",
        "            answer_len_deltas[ref_model_name] = (group['reference_len'] - group['model_len']).std()\n",
        "\n",
        "    for _, group in df.groupby('model_hash'):\n",
        "        for _, subgroup in group.groupby('full_hash'):\n",
        "            # assert subgroup.shape[0] == 2\n",
        "            if (subgroup['model_name'] == subgroup['reference_model_name']).all():\n",
        "                continue\n",
        "            pred = int(subgroup['p'].mean() >= 0.5)\n",
        "            if style_control:\n",
        "                data.append([subgroup['model_name'].tolist()[0], subgroup['reference_model_name'].tolist()[0], pred, subgroup['model_style'].tolist()[0], subgroup['reference_style'].tolist()[0]])\n",
        "            else:\n",
        "                normalized_answer_delta_weight = 0.5\n",
        "                if len_control and (pred or not pen_only_model):\n",
        "                    normalized_answer_delta_weight = 0.5\n",
        "                    answers_length_deltas_std = answer_len_deltas[subgroup['reference_model_name'].iloc[0]]\n",
        "                    answer_length_delta = (subgroup['reference_len'] - subgroup['model_len']).iloc[0]\n",
        "                    if answer_length_delta != 0: # same model as ref\n",
        "                        normalized_answer_delta_weight = expit(answer_length_delta / answers_length_deltas_std)\n",
        "                data.append([subgroup['model_name'].tolist()[0], subgroup['reference_model_name'].tolist()[0], pred, normalized_answer_delta_weight])\n",
        "    return data"
      ],
      "metadata": {
        "id": "_JTKv6cXQgB4"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def right_columns(df: pd.DataFrame, columns: list[str]) -> bool:\n",
        "    if df.empty:\n",
        "        return False\n",
        "    for c in columns:\n",
        "        if c not in df.columns:\n",
        "            return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "xuejwxCZpAFa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models_from_data(df: pd.DataFrame) -> list[str]:\n",
        "    if right_columns(df, ['model_a', 'model_b']):\n",
        "        return pd.concat([df.model_a, df.model_b]).unique().tolist()\n",
        "    return []"
      ],
      "metadata": {
        "id": "YK_nKZscZ_6C"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _calculate_mean_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # taken from https://github.com/VikhrModels/ru_llm_arena/blob/master/show_result.py\n",
        "    if not right_columns(df, ['model_a', 'model_b', 'winner', 'answer_deltas']):\n",
        "        print(\"Error in dataframe while computing mean scores.\")\n",
        "        return pd.DataFrame()\n",
        "    df['winner'] = df['winner'].map({\n",
        "            1: Winner.X,\n",
        "            0: Winner.Y\n",
        "    })\n",
        "    result = bradley_terry(\n",
        "        df['model_a'],\n",
        "        df['model_b'],\n",
        "        df['winner'],\n",
        "        weights=df['answer_deltas'],\n",
        "        tolerance=1e-8\n",
        "    )\n",
        "    df = pairwise_frame(result.scores)\n",
        "    np.fill_diagonal(df.values, np.nan)\n",
        "    return df\n",
        "\n",
        "def _calculate_ratings(\n",
        "    results: List[Dict]=[],\n",
        "    style_control: bool=True,\n",
        "    len_control: bool=False,\n",
        "    pen_only_model: bool=False,\n",
        "    get_mean_scores: bool=True,\n",
        "    get_elo_ratings: bool=True,\n",
        "    model: str='',\n",
        "  ) -> Dict:\n",
        "    '''\n",
        "    На вход подаются\n",
        "    results = [\n",
        "        {\n",
        "            'p': <model_proba_i>,\n",
        "            'id': <id_i>,\n",
        "            'model_name': <model_name_i>,\n",
        "            'reference_model_name': <reference_model_name_i>,\n",
        "            'styles': {\n",
        "                'model':      [x, x, x, x, x],\n",
        "                'reference':  [x, x, x, x, x], # [ len_answer, header_count, list_count, bold_count, code_blocks_count ]\n",
        "            }\n",
        "        } for i in range(2*n*m) # на каждый instruction было по 2 sample\n",
        "    ]\n",
        "    '''\n",
        "    if not results:\n",
        "        raise ValueError(\"No data for computing!\")\n",
        "    data = _prepare_data(results, len_control=len_control, style_control=style_control, pen_only_model=pen_only_model)\n",
        "    if not data:\n",
        "        raise ValueError(\"No data for computing!\")\n",
        "    scores = {'elo': {}, 'mean_scores': {}}\n",
        "    if style_control:\n",
        "        df = pd.DataFrame(data, columns=['model_a', 'model_b', 'winner', 'model_a_style', 'model_b_style'])\n",
        "    else:\n",
        "        df = pd.DataFrame(data, columns=['model_a', 'model_b', 'winner', 'answer_deltas'])\n",
        "    models = get_models_from_data(df)\n",
        "    if model and model not in models:\n",
        "        raise ValueError(f\"Model {model} is not in dataset!\")\n",
        "    if style_control:\n",
        "        ratings, models, context_logits = compute_style_control(df)\n",
        "        df['answer_deltas'] = context_logits\n",
        "        scaled_ratings = scale_and_offset(ratings)\n",
        "        if get_elo_ratings:\n",
        "            for i in range(len(models)):\n",
        "                scores['elo'][models[i]] = scaled_ratings[i]\n",
        "    if get_mean_scores:\n",
        "        df = _calculate_mean_scores(df)\n",
        "        if df.empty:\n",
        "            print(scores)\n",
        "            print('Error in calculating mean scores.')\n",
        "        if model:\n",
        "            scores['mean_scores'][model] = df.loc[model].mean()\n",
        "        else:\n",
        "            for m in models:\n",
        "                scores['mean_scores'][m] = df.loc[m].mean()\n",
        "    return scores"
      ],
      "metadata": {
        "id": "25PtsVbJBbax"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results_from_file(filename) -> List[Dict]:\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        results: List[Dict] = json.load(file)\n",
        "        return results"
      ],
      "metadata": {
        "id": "NKTqcqHcftue"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratings(\n",
        "    sourse_files: Union[str, list[str]],\n",
        "    model: str='',\n",
        "    save_all_battles: bool=True,\n",
        "    newfilename: str='',\n",
        "    answerfile: str='',\n",
        "    load_results: bool=True,\n",
        "    print_results: bool=True,\n",
        "    style_control: bool=True,\n",
        "    len_control: bool=False,\n",
        "    no_control: bool=False,\n",
        "    pen_only_model: bool=False,\n",
        "    get_mean_scores: bool=True,\n",
        "    get_elo_ratings: bool=True\n",
        "):\n",
        "    if not load_results and not print_results:\n",
        "        raise ValueError(\"No task!\")\n",
        "    if not sourse_files:\n",
        "        raise ValueError(\"No data available for analysis.\")\n",
        "    results = []\n",
        "    if isinstance(sourse_files, str):\n",
        "        sourse_files = [sourse_files]\n",
        "    if isinstance(sourse_files, list):\n",
        "        read_files_count = 0\n",
        "        for file in sourse_files:\n",
        "            try:\n",
        "                results += get_results_from_file(file)\n",
        "            except (FileNotFoundError, IsADirectoryError):\n",
        "                print(f\"File {file} was not found or is empty.\")\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Error: {file} is not JSON-format.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error with file {file}: {e}\")\n",
        "            else:\n",
        "                read_files_count += 1\n",
        "        if read_files_count == len(sourse_files):\n",
        "            print(\"All data has been received.\")\n",
        "    if not results:\n",
        "        raise ValueError(\"No data for computing!\")\n",
        "    if save_all_battles:\n",
        "        save_battles_to_json(newfilename, results)\n",
        "    if not (style_control or len_control or no_control) and not (get_elo_ratings or get_mean_scores):\n",
        "        raise ValueError(\"No option selectes.\")\n",
        "    if no_control:\n",
        "        style_control, len_control = False, False\n",
        "        get_elo_ratings = False\n",
        "        get_mean_scores = True\n",
        "    if style_control:\n",
        "        len_control = False\n",
        "    if len_control:\n",
        "        get_elo_ratings = False\n",
        "        get_mean_scores = True\n",
        "        style_control = False\n",
        "    scores = _calculate_ratings(\n",
        "        results=results,\n",
        "        model=model,\n",
        "        style_control=style_control,\n",
        "        len_control=len_control,\n",
        "        pen_only_model=pen_only_model,\n",
        "        get_mean_scores=get_mean_scores,\n",
        "        get_elo_ratings=get_elo_ratings)\n",
        "    if not get_elo_ratings:\n",
        "        scores.pop(\"elo\", None)\n",
        "    if not get_mean_scores:\n",
        "        scores.pop(\"mean_scores\", None)\n",
        "    if print_results:\n",
        "        if get_elo_ratings:\n",
        "            print('ELO RATINGS:')\n",
        "            for m in scores['elo']:\n",
        "                print(f\"{str(m):40} | {scores['elo'][m]}\")\n",
        "            print()\n",
        "        if get_mean_scores:\n",
        "            print('MEAN SCORES:')\n",
        "            for m in scores['mean_scores']:\n",
        "                print(f\"{str(m):40} | {scores['mean_scores'][m]}\")\n",
        "            print()\n",
        "    if load_results:\n",
        "        if not answerfile:\n",
        "            answerfile = 'results.json'\n",
        "        with open(answerfile, \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(scores, file, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "l4HUpvlFdmM1"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratings(\n",
        "    sourse_files=\"previous_battles.json\",\n",
        "    model='',\n",
        "    save_all_battles=True,\n",
        "    newfilename='',\n",
        "    answerfile='',\n",
        "    load_results=True,\n",
        "    print_results=True,\n",
        "    style_control=True,\n",
        "    len_control=False,\n",
        "    no_control=True,\n",
        "    pen_only_model=False,\n",
        "    get_mean_scores=False,\n",
        "    get_elo_ratings=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDsyoF_ouhen",
        "outputId": "45830c2e-2b04-486c-9413-f4990abd08a4"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data has been received.\n",
            "Data was stored to battles_saved_file.json.\n",
            "MEAN SCORES:\n",
            "Qwen2.5-32B-Instruct                     | 0.3587421789282791\n",
            "RuadaptQwen2.5-32B-Pro-Beta              | 0.6633075218114936\n",
            "RuadaptQwen2.5-7B-Lite-Beta              | 0.580000368883008\n",
            "gigachat_max_26.20_uncen                 | 0.47070365701733685\n",
            "gpt-4-1106-preview                       | 0.5577940168943933\n",
            "gpt-4o-mini                              | 0.3917601471368512\n",
            "llama3-70b                               | 0.5789097690632004\n",
            "tlite                                    | 0.5443629814896822\n",
            "tpro                                     | 0.7075199912293207\n",
            "vikhr12b                                 | 0.49790500762108836\n",
            "yagpt5lite                               | 0.14899435992534638\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IaUQfNLVx99a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}